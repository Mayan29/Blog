# 第四章 视频播放

## 1. 主要框架

### AVPlayer

AV Foundation 的播放都围绕 AVPlayer 类展开，AVPlayer 是一个用来播放基于时间的视听媒体的控制器对象，支持播放从本地、分布下载或通过 HTTP Live Streaming 协议得到的流媒体。

AVPlayer 是一个不可见组件，如果播放音频文件，没有可视化的用户界面也不会有什么问题，如果播放视频文件，要将视频资源导出到用户界面，需要使用 AVPlayerLayer 类。

> AVPlayer 只管理一个单独资源的播放，不过框架还提供了 AVPlayer 的一个子类 AVQueuePlayer，可以用来管理一个资源队列。当你需要在一个序列中播放多个条目或者为音频、视频资源设置播放循环时可使用该子类。

### AVPlayerLayer

AVPlayerLayer 构建于 Core Animation 之上，Core Animation 本身具有基于时间的属性，并且由于它基于 OpenGL，所以具有很好的性能，能非常好地满足 AV Foundation 的各种需要。

AVPlayerLayer 使用起来简单，开发者可以自定义的只有 videoGravity 属性，用来确定视频的拉伸或缩放程度。

### AVPlayerItem

我们最终的目的是使用 AVPlayer 播放 AVAsset。但是 AVAsset 只包含媒体资源的静态信息，无法实现播放功能，所以，需要通过 AVPlayerItem 和 AVPlayerItemTrack 构建响应的动态内容。

AVPlayerItem 会建立媒体资源动态视角的数据模型，保存 AVPlayer 在播放时呈现的状态。AVPlayerItem 由一个或者多个媒体曲目组成，由 AVPlayerItemTrack 类建立模型。AVPlayerItemTrack 实例用于表示播放器条目中的类型统一的媒体流，比如音频或者视频。AVPlayerItem 中的曲目直接与基础 AVAsset 中的 AVAssetTrack 实例相对应。

## 2. 视频播放

```objc
- (void)viewDidLoad {
    [super viewDidLoad];
   
    // AVPlayerItem：提供数据
    NSURL *assetURL = [[NSBundle mainBundle] URLForResource:@"一骑当千01" withExtension:@"mp4"];
    AVAsset *asset = [AVAsset assetWithURL:assetURL];
    AVPlayerItem *playerItem = [AVPlayerItem playerItemWithAsset:asset];
    [playerItem addObserver:self forKeyPath:@"status" options:0 context:nil];
    
    // AVPlayer：控制播放
    _player = [AVPlayer playerWithPlayerItem:playerItem];
    
    // AVPlayerLayer：显示播放
    AVPlayerLayer *playerLayer = [AVPlayerLayer playerLayerWithPlayer:_player];
    playerLayer.frame = self.view.bounds;
    [self.view.layer addSublayer:playerLayer];
}

- (void)observeValueForKeyPath:(NSString *)keyPath ofObject:(id)object change:(NSDictionary<NSKeyValueChangeKey,id> *)change context:(void *)context
{
    if ([keyPath isEqualToString:@"status"]) {
        
        AVPlayerItem *playerItem = (AVPlayerItem *)object;
        if (playerItem.status == AVPlayerItemStatusReadyToPlay) {            
            [self.player play];
        }
    }
}
```

## 3. 时间处理

AVAudioPlayer 使用 NSTimeInterval 表示时间，但是 double 类型的运算会导致不精确的情况。此外，double 类型呈现时间信息无法做到自我描述，这就导致在使用不同时间轴进行比较和运算时比较困难。所以 AV Foundation 使用一种可靠性更高的方法来展示时间信息，这就是 CMTime

```objc
typedef struct {
	CMTimeValue	value;		
	CMTimeScale	timescale;	
	CMTimeFlags	flags;		
	CMTimeEpoch	epoch;	
} CMTime;
```

CMTime 是一种结构体，最关键的两个值为 value 和 timescale，value 是一个 64 位整数值，timescale 是一个 32 位整数值，分别为分子和分母。

```objc
// 0.5 s
CMTime halfSecond = CMTimeMake(1, 2);

// 5 s
CMTime fiveSeconds = CMTimeMake(5, 1);

// 44.1 kHz
CMTime oneSample = CMTimeMake(1, 44100);

// Zero time value
CMTime zeroTime = kCMTimeZero;
```









